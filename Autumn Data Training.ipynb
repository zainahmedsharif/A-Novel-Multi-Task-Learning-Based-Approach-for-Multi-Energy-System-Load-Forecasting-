{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8c2237bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import datetime as dt\n",
    "import random\n",
    "import os \n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, GRU,LSTM, Dense,Lambda,Conv1D\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from keras.layers import AdditiveAttention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from pytorch_tcn import TCN\n",
    "\n",
    "TRAIN_STEPS = 168\n",
    "OUTPUT_STEPS = 1\n",
    "OFFSET = 1\n",
    "LSTM_DIM = 64\n",
    "MAX_EPOCH = 200\n",
    "BATCH_SIZE = 32\n",
    "LEA_RAT = 0.01\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device is:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79609112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "750579f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = r'C:\\\\Users\\\\Zain Ahmed\\\\Desktop\\\\Newest Paper\\\\*.csv'\n",
    "data = pd.DataFrame()\n",
    "\n",
    "METRO_FILE_DIR = r'C:\\\\Users\\\\Zain Ahmed\\\\Desktop\\\\Newest Paper\\\\Metrodata\\\\*.csv'\n",
    "metro_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d982d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(glob.glob(FILE_DIR))):\n",
    "    df = pd.read_csv(glob.glob(FILE_DIR)[i])\n",
    "    data = pd.concat([data,df],ignore_index=True)\n",
    "    \n",
    "for i in range(len(glob.glob(METRO_FILE_DIR))):\n",
    "    metro_df = pd.read_csv(glob.glob(METRO_FILE_DIR)[i],skiprows=2)\n",
    "    metro_data = pd.concat([metro_data,metro_df],ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1822a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_data = metro_data[metro_data['Minute'] != 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2779a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_data\n",
    "data['datetime'] = data['Year'].astype('str') +  '-' + data['Month'].astype('str') + '-' + data['Day'].astype('str') + '-' + data['Hour'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ce974162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campus</th>\n",
       "      <th>bldgno</th>\n",
       "      <th>bldgname</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>KW</th>\n",
       "      <th>KWS</th>\n",
       "      <th>...</th>\n",
       "      <th>HTmmBTU#Houses</th>\n",
       "      <th>HTmmBTUlightbulbs</th>\n",
       "      <th>HTmmBTUgalsgas</th>\n",
       "      <th>Total#Houses</th>\n",
       "      <th>Totallightbulbs</th>\n",
       "      <th>Totalgalsgas</th>\n",
       "      <th>GHG</th>\n",
       "      <th>DOW</th>\n",
       "      <th>tstamp2</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16333.65</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>301459.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>7769.0</td>\n",
       "      <td>1942125.0</td>\n",
       "      <td>16668.0</td>\n",
       "      <td>8.868</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01T00:00:00.000</td>\n",
       "      <td>2016-1-1-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16228.42</td>\n",
       "      <td>1.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>308012.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>7734.0</td>\n",
       "      <td>1933276.0</td>\n",
       "      <td>16406.0</td>\n",
       "      <td>8.811</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01T01:00:00.000</td>\n",
       "      <td>2016-1-1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16397.60</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>312852.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7723.0</td>\n",
       "      <td>1930582.0</td>\n",
       "      <td>15798.0</td>\n",
       "      <td>8.903</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01T02:00:00.000</td>\n",
       "      <td>2016-1-1-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16317.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>321361.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7592.0</td>\n",
       "      <td>1897781.0</td>\n",
       "      <td>14657.0</td>\n",
       "      <td>8.859</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01T03:00:00.000</td>\n",
       "      <td>2016-1-1-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16316.95</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>327655.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>7620.0</td>\n",
       "      <td>1904866.0</td>\n",
       "      <td>14683.0</td>\n",
       "      <td>8.862</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01T04:00:00.000</td>\n",
       "      <td>2016-1-1-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>15116.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>251720.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>7329.0</td>\n",
       "      <td>1832042.0</td>\n",
       "      <td>17397.0</td>\n",
       "      <td>8.207</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-31T19:00:00.000</td>\n",
       "      <td>2019-12-31-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>14852.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>259767.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7233.0</td>\n",
       "      <td>1808063.0</td>\n",
       "      <td>16952.0</td>\n",
       "      <td>8.066</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-31T20:00:00.000</td>\n",
       "      <td>2019-12-31-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>14680.53</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>266104.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>7101.0</td>\n",
       "      <td>1774987.0</td>\n",
       "      <td>16072.0</td>\n",
       "      <td>7.966</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-31T21:00:00.000</td>\n",
       "      <td>2019-12-31-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>14359.63</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>253571.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>6880.0</td>\n",
       "      <td>1719802.0</td>\n",
       "      <td>15413.0</td>\n",
       "      <td>7.798</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-31T22:00:00.000</td>\n",
       "      <td>2019-12-31-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>14169.47</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>975.0</td>\n",
       "      <td>243753.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>6732.0</td>\n",
       "      <td>1682873.0</td>\n",
       "      <td>14964.0</td>\n",
       "      <td>7.694</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-31T23:00:00.000</td>\n",
       "      <td>2019-12-31-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      campus  bldgno bldgname tstamp  Year  Month  Day  Hour        KW   KWS  \\\n",
       "0      Tempe     NaN                  2016      1    1     0  16333.65  1.32   \n",
       "1      Tempe     NaN                  2016      1    1     1  16228.42  1.29   \n",
       "2      Tempe     NaN                  2016      1    1     2  16397.60  1.30   \n",
       "3      Tempe     NaN                  2016      1    1     3  16317.28  1.32   \n",
       "4      Tempe     NaN                  2016      1    1     4  16316.95  1.30   \n",
       "...      ...     ...      ...    ...   ...    ...  ...   ...       ...   ...   \n",
       "35058  Tempe     NaN                  2019     12   31    19  15116.80  0.94   \n",
       "35059  Tempe     NaN                  2019     12   31    20  14852.98  0.95   \n",
       "35060  Tempe     NaN                  2019     12   31    21  14680.53  0.90   \n",
       "35061  Tempe     NaN                  2019     12   31    22  14359.63  0.83   \n",
       "35062  Tempe     NaN                  2019     12   31    23  14169.47  1.26   \n",
       "\n",
       "       ...  HTmmBTU#Houses  HTmmBTUlightbulbs  HTmmBTUgalsgas  Total#Houses  \\\n",
       "0      ...          1206.0           301459.0           115.0        7769.0   \n",
       "1      ...          1232.0           308012.0           118.0        7734.0   \n",
       "2      ...          1252.0           312852.0           120.0        7723.0   \n",
       "3      ...          1286.0           321361.0           123.0        7592.0   \n",
       "4      ...          1311.0           327655.0           125.0        7620.0   \n",
       "...    ...             ...                ...             ...           ...   \n",
       "35058  ...          1007.0           251720.0            96.0        7329.0   \n",
       "35059  ...          1039.0           259767.0            99.0        7233.0   \n",
       "35060  ...          1065.0           266104.0           102.0        7101.0   \n",
       "35061  ...          1015.0           253571.0            97.0        6880.0   \n",
       "35062  ...           975.0           243753.0            93.0        6732.0   \n",
       "\n",
       "       Totallightbulbs  Totalgalsgas    GHG  DOW                  tstamp2  \\\n",
       "0            1942125.0       16668.0  8.868    6  2016-01-01T00:00:00.000   \n",
       "1            1933276.0       16406.0  8.811    6  2016-01-01T01:00:00.000   \n",
       "2            1930582.0       15798.0  8.903    6  2016-01-01T02:00:00.000   \n",
       "3            1897781.0       14657.0  8.859    6  2016-01-01T03:00:00.000   \n",
       "4            1904866.0       14683.0  8.862    6  2016-01-01T04:00:00.000   \n",
       "...                ...           ...    ...  ...                      ...   \n",
       "35058        1832042.0       17397.0  8.207    3  2019-12-31T19:00:00.000   \n",
       "35059        1808063.0       16952.0  8.066    3  2019-12-31T20:00:00.000   \n",
       "35060        1774987.0       16072.0  7.966    3  2019-12-31T21:00:00.000   \n",
       "35061        1719802.0       15413.0  7.798    3  2019-12-31T22:00:00.000   \n",
       "35062        1682873.0       14964.0  7.694    3  2019-12-31T23:00:00.000   \n",
       "\n",
       "            datetime  \n",
       "0         2016-1-1-0  \n",
       "1         2016-1-1-1  \n",
       "2         2016-1-1-2  \n",
       "3         2016-1-1-3  \n",
       "4         2016-1-1-4  \n",
       "...              ...  \n",
       "35058  2019-12-31-19  \n",
       "35059  2019-12-31-20  \n",
       "35060  2019-12-31-21  \n",
       "35061  2019-12-31-22  \n",
       "35062  2019-12-31-23  \n",
       "\n",
       "[35063 rows x 30 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "535c5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime'] = data['Year'].astype('str') +  '-' + data['Month'].astype('str') + '-' + data['Day'].astype('str') + '-' + data['Hour'].astype('str')\n",
    "data['datetime']=pd.to_datetime(data['datetime'],format='%Y-%m-%d-%H')\n",
    "\n",
    "\n",
    "metro_data['datetime'] = metro_data['Year'].astype('str') +  '-' + metro_data['Month'].astype('str') + '-' + metro_data['Day'].astype('str') + '-' + metro_data['Hour'].astype('str')\n",
    "metro_data['datetime']=pd.to_datetime(metro_data['datetime'],format='%Y-%m-%d-%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "638d072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('datetime')\n",
    "metro_data = metro_data.set_index('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3cbd4769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KW           7\n",
       "HTmmBTU    141\n",
       "CHWTON       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['KW','HTmmBTU','CHWTON']]\n",
    "Qu_1 = data.quantile(0.25)\n",
    "Qu_3 = data.quantile(0.75)\n",
    "IQR = Qu_3 - Qu_1\n",
    "((data<(Qu_1 - 3.0 * IQR)) | (data>(Qu_3 + 2.0 * IQR))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2dd75a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[(data<(Qu_1 - 2.0 * IQR) | (data>(Qu_3 - 2.0 * IQR)))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9296e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[((data<(Qu_1 - 2.0 * IQR)) | (data>(Qu_3 + 2.0 * IQR)))] = np.nan \n",
    "data.loc[data['KW']==0,'KW'] = np.nan\n",
    "data.loc[data['HTmmBTU']==0,'HTmmBTU'] = np.nan\n",
    "data.loc[data['CHWTON']==0,'CHWTON'] = np.nan\n",
    "\n",
    "data.fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc787f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "15386520",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge=pd.merge(data,metro_data, how='inner', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a5eea091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merge\n",
    "data['HTmmBTU'] = data['HTmmBTU'] * 293.07\n",
    "data['CHWTON'] = data['CHWTON'] * 3.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9ff2259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['KW_last_hour'] = data['KW'].shift()\n",
    "data['HTmmBTU_last_hour'] = data['HTmmBTU'].shift()\n",
    "data['CHWTON_last_hour'] = data['CHWTON'].shift()\n",
    "data['KW_last_2_hour'] = data['KW'].shift(2)\n",
    "data['HTmmBTU_last_2_hour'] = data['HTmmBTU'].shift(2)\n",
    "data['CHWTON_last_2_hour'] = data['CHWTON'].shift(2)\n",
    "data['KW_last_day'] = data['KW'].shift(24)\n",
    "data['HTmmBTU_last_day'] = data['HTmmBTU'].shift(24)\n",
    "data['CHWTON_last_day'] = data['CHWTON'].shift(24)\n",
    "data['KW_last_week'] = data['KW'].shift(168)\n",
    "data['HTmmBTU_last_week'] = data['HTmmBTU'].shift(168)\n",
    "data['CHWTON_last_week'] = data['CHWTON'].shift(168)\n",
    "data['KW_last_year'] = data.groupby([data.index.month,data.index.day,data.index.hour])['KW'].shift()\n",
    "data['HTmmBTU_last_year'] = data.groupby([data.index.month,data.index.day,data.index.hour])['HTmmBTU'].shift()\n",
    "data['CHWTON_last_year'] = data.groupby([data.index.month,data.index.day,data.index.hour])['CHWTON'].shift()\n",
    "data.fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "86a58b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will divide the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f41df052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['HTmmBTU'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eeed14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spring_data = data[(data['Month']>2) & (data['Month']<6)]\n",
    "spring_data.name = 'spring_data'\n",
    "\n",
    "\n",
    "summer_data = data[(data['Month']>5) & (data['Month']<9)]\n",
    "summer_data.name = 'summer_data'\n",
    "\n",
    "\n",
    "autumn_data = data[(data['Month']>8) & (data['Month']<12)]\n",
    "autumn_data.name = 'autumn_data'\n",
    "\n",
    "\n",
    "\n",
    "winter_data = data[(data['Month']>11) | (data['Month']<3)]\n",
    "winter_data.name = 'winter_data'\n",
    "    \n",
    "\n",
    "def rolling_window(array_data_real,input_size,output_size,offset,out=[],inp=['C','H','E']):\n",
    "    '''\n",
    "    The function takes a series array_data of size (size,) \n",
    "\n",
    "    and generates\n",
    "    \n",
    "    a array of size (input_size,((array_size-(input_size+output_size)/stride)+1)) as inputs \n",
    "    \n",
    "    and array of size (array_size-(input_size+output_size)/stride)+1)as output \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    array_data = array_data_real.copy(deep=True) \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    scaler = scaler.fit(array_data)\n",
    "    \n",
    "    array_data_scaled = pd.DataFrame(scaler.transform(array_data),columns = array_data.columns)\n",
    "    \n",
    "    if ('C' not in inp) & ('C' not in out):        \n",
    "        array_data_scaled.drop('CHWTON',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('CHWTON_last_hour',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('CHWTON_last_2_hour',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('CHWTON_last_day',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('CHWTON_last_week',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('CHWTON_last_year',inplace=True,axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "    if ('H' not in inp) & ('H' not in out):\n",
    "            \n",
    "        array_data_scaled.drop('HTmmBTU',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('HTmmBTU_last_hour',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('HTmmBTU_last_2_hour',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('HTmmBTU_last_day',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('HTmmBTU_last_week',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('HTmmBTU_last_year',inplace=True,axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "    if ('E' not in inp) & ('E' not in out):   \n",
    "        array_data_scaled.drop('KW',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('KW_last_hour',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('KW_last_2_hour',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('KW_last_day',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('KW_last_week',inplace=True,axis=1)\n",
    "        array_data_scaled.drop('KW_last_year',inplace=True,axis=1)\n",
    "\n",
    "            \n",
    "\n",
    "#     lab_data = array_data[:,0]\n",
    "    \n",
    "#     for i in range(input_size,len(array_data)-output_size+1,offset):\n",
    "            \n",
    "#             data.append(array_data[i-input_size:i,0:array_data.shape[1]])\n",
    "    \n",
    "#             labels.append(lab_data[i:i+output_size])\n",
    "\n",
    "        \n",
    "    data_idx = sliding_window_view(np.arange(array_data_scaled.to_numpy().shape[0]).reshape(-1),window_shape=input_size)[::offset][:-1]\n",
    "    \n",
    "    data = array_data_scaled.to_numpy()[data_idx]\n",
    "    \n",
    "    if 'C' in out:\n",
    "        \n",
    "        out_array = array_data_scaled['CHWTON'].to_numpy()\n",
    "        \n",
    "        labels = sliding_window_view(out_array[input_size:].reshape(-1),window_shape=output_size)[::offset]\n",
    "        \n",
    "    if 'H' in out:\n",
    "        \n",
    "        out_array = array_data_scaled['HTmmBTU'].to_numpy()\n",
    "\n",
    "        labels = sliding_window_view(out_array[input_size:].reshape(-1),window_shape=output_size)[::offset]\n",
    "    \n",
    "    if 'E' in out:\n",
    "        \n",
    "        out_array = array_data_scaled['KW'].to_numpy()\n",
    "\n",
    "        labels = sliding_window_view(out_array[input_size:].reshape(-1),window_shape=output_size)[::offset]\n",
    "    \n",
    "    data = data.astype(np.float64)\n",
    "        \n",
    "    labels = labels.astype(np.float64)\n",
    "        \n",
    "    return data,labels,scaler,array_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a8b75eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Spring Data\n",
    "\n",
    "tr_id = int((autumn_data.shape[0]*0.80)/24)*24\n",
    "val_id = int((autumn_data.shape[0]*0.90)/24)*24\n",
    "tra_data = autumn_data.iloc[:tr_id,:]\n",
    "val_data = autumn_data.iloc[tr_id:val_id,:]\n",
    "tes_data = autumn_data.iloc[val_id:,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "34263828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start with the Summer Data. The Heat Map for summer data shows a high MIC between Electric and \n",
    "## Cooling load so we will utilize that alongwith other factors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cb8f8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Heating Summer Data\n",
    "\n",
    "heat_tra_data_sli,heat_tra_lab,heat_tra_sca,heat_tra_stan = rolling_window(tra_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['H'],inp=['C','H','E'])\n",
    "heat_val_data_sli,heat_val_lab,heat_val_sca,heat_val_stan = rolling_window(val_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['H'],inp=['C','H','E'])\n",
    "heat_tes_data_sli,heat_tes_lab,heat_test_scaler,heat_tes_stan = rolling_window(tes_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['H'],inp=['C','H','E'])\n",
    "\n",
    "## Cooling Data Summer\n",
    "\n",
    "cool_tra_data_sli,cool_tra_lab,cool_tra_sca,col_tra_stan = rolling_window(tra_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['C'],inp=['C','H','E'])\n",
    "cool_val_data_sli,cool_val_lab,cool_val_sca,cool_val_stan = rolling_window(val_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['C'],inp=['C','H','E'])\n",
    "cool_tes_data_sli,cool_tes_lab,cool_test_scaler,cool_tes_stan = rolling_window(tes_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['C'],inp=['C','H','E'])\n",
    "\n",
    "## Electric Data Summer\n",
    "\n",
    "elec_tra_data_sli,elec_tra_lab,elec_tra_sca,elec_tra_stan = rolling_window(tra_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['E'],inp=['C','H','E'])\n",
    "elec_val_data_sli,elec_val_lab,elec_val_sca,elec_val_stan = rolling_window(val_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['E'],inp=['C','H','E'])\n",
    "elec_tes_data_sli,elec_tes_lab,elec_test_scaler,elec_tes_stan = rolling_window(tes_data,input_size=TRAIN_STEPS,output_size=OUTPUT_STEPS,offset=OFFSET,out=['E'],inp=['C','H','E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3bbb8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dataset(x1,y1,x2,y2,x3,y3,b_size):\n",
    "    \n",
    "    '''\n",
    "    Takes inputs and labels for 3 different datasets and returns a dataloader object\n",
    "    \n",
    "    x1,y1 = heat\n",
    "    \n",
    "    x2,y2 = cool\n",
    "    \n",
    "    x3,y3 = elec\n",
    "    '''\n",
    "    \n",
    "    x1_tensor = torch.from_numpy(x1).float()\n",
    "    \n",
    "    y1_tensor = torch.from_numpy(y1).float()\n",
    "    \n",
    "    x2_tensor = torch.from_numpy(x2).float()\n",
    "    \n",
    "    y2_tensor = torch.from_numpy(y2).float()\n",
    "    \n",
    "    x3_tensor = torch.from_numpy(x3).float()\n",
    "    \n",
    "    y3_tensor = torch.from_numpy(y3).float()\n",
    "    \n",
    "    dataset = TensorDataset(x1_tensor,y1_tensor,x2_tensor,y2_tensor,x3_tensor,y3_tensor)\n",
    "    \n",
    "    my_dataloader = DataLoader(dataset,batch_size=b_size)\n",
    "    \n",
    "    return my_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "25c63ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = array_to_dataset(heat_tra_data_sli,heat_tra_lab,cool_tra_data_sli,cool_tra_lab,elec_tra_data_sli,elec_tra_lab,b_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "974a83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = array_to_dataset(heat_val_data_sli,heat_val_lab,cool_val_data_sli,cool_val_lab,elec_val_data_sli,elec_val_lab,b_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "165e6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_dataloader = array_to_dataset(heat_tes_data_sli,heat_tes_lab,cool_tes_data_sli,cool_tes_lab,elec_tes_data_sli,elec_tes_lab,b_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2ec30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a3f3f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heat_loader_train = array_to_dataloader(heat_tra_data_sli,heat_tra_lab,b_size=BATCH_SIZE)\n",
    "#heat_loader_val = array_to_dataloader(heat_val_data_sli,cool_val_lab,b_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "72f63116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cool_loader_train = array_to_dataloader(cool_tra_data_sli,cool_tra_lab,b_size=BATCH_SIZE)\n",
    "#cool_loader_val = array_to_dataloader(cool_val_data_sli,cool_val_lab,b_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "134bf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elec_loader_train = array_to_dataloader(elec_tra_data_sli,elec_tra_lab,b_size=BATCH_SIZE)\n",
    "#elec_loader_val = array_to_dataloader(elec_val_data_sli,elec_val_lab,b_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5715a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = torch.utils.data.TensorDataset(heat_loader_train, heat_loader_val,cool_loader_train,cool_loader_val,elec_loader_train,elec_loader_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fad4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b05e699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,train_steps,heat_feature,cool_feature,elec_feature,lstm_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_steps = train_steps\n",
    "        \n",
    "        self.heat_feature = heat_feature\n",
    "        \n",
    "        self.cool_feature = cool_feature\n",
    "        \n",
    "        self.elec_feature = elec_feature\n",
    "        \n",
    "        self.lstm_dim = lstm_dim\n",
    "        \n",
    "        self.input_1 = TCN(num_inputs=heat_feature,num_channels=[32,self.lstm_dim],kernel_size=8,dropout=0.2,input_shape= 'NLC',use_skip_connections='True',activation='leaky_relu')\n",
    "        \n",
    "        self.input_2 = TCN(num_inputs=cool_feature,num_channels=[32,self.lstm_dim],kernel_size=8,dropout=0.2,input_shape= 'NLC',use_skip_connections='True',activation='leaky_relu')\n",
    "        \n",
    "        self.input_3 = TCN(num_inputs=elec_feature,num_channels=[32,self.lstm_dim],kernel_size=8,dropout=0.2,input_shape= 'NLC',use_skip_connections='True',activation='leaky_relu')\n",
    "        \n",
    "        self.flatten_layer = nn.Flatten(start_dim=1)\n",
    "        \n",
    "        self.fully = nn.Linear(3*self.lstm_dim,3)\n",
    "        \n",
    "        ####USING LEAKY RELU\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "                \n",
    "    def forward(self,heat_input,cool_input,elec_input):\n",
    "        \n",
    "        out_hea = self.input_1(heat_input)\n",
    "        \n",
    "        out_coo = self.input_2(cool_input)\n",
    "\n",
    "        out_ele = self.input_3(elec_input)\n",
    "        \n",
    "#        print('Output Layer Shape is ',out_hea.shape)\n",
    "\n",
    "        concat_layer = torch.cat((self.flatten_layer(out_hea[:,-1,:]),self.flatten_layer(out_coo[:,-1,:]),self.flatten_layer(out_ele[:,-1,:])),1)\n",
    "        \n",
    "#        print('Concat Layer Shape is ',concat_layer.shape)\n",
    "\n",
    "        feature_sharing_layer = self.fully(concat_layer)\n",
    "        \n",
    "        final_output = self.relu(feature_sharing_layer)\n",
    "        \n",
    "#        print('Final Output Shape is ',final_output.shape)\n",
    "        \n",
    "        output_heat = final_output[:,0].unsqueeze(1)\n",
    "        \n",
    "#        print('Heat Output Shape is ',output_heat.shape)\n",
    "        \n",
    "        output_cool = final_output[:,1].unsqueeze(1)\n",
    "        \n",
    "        output_elec = final_output[:,2].unsqueeze(1)\n",
    "        \n",
    "        return output_heat,output_cool,output_elec\n",
    "    \n",
    "HEA_FEA = int(heat_tra_data_sli.shape[2])\n",
    "COO_FEA = int(cool_tra_data_sli.shape[2])\n",
    "ELE_FEA = int(elec_tra_data_sli.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "56e11924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─TCN: 1-1                                    --\n",
      "|    └─ModuleList: 2-1                        --\n",
      "|    |    └─Conv1d: 3-1                       2,112\n",
      "|    └─LeakyReLU: 2-2                         --\n",
      "|    └─ModuleList: 2-3                        --\n",
      "|    |    └─TemporalBlock: 3-2                16,704\n",
      "|    |    └─TemporalBlock: 3-3                51,520\n",
      "├─TCN: 1-2                                    --\n",
      "|    └─ModuleList: 2-4                        --\n",
      "|    |    └─Conv1d: 3-4                       2,112\n",
      "|    └─LeakyReLU: 2-5                         --\n",
      "|    └─ModuleList: 2-6                        --\n",
      "|    |    └─TemporalBlock: 3-5                16,704\n",
      "|    |    └─TemporalBlock: 3-6                51,520\n",
      "├─TCN: 1-3                                    --\n",
      "|    └─ModuleList: 2-7                        --\n",
      "|    |    └─Conv1d: 3-7                       2,112\n",
      "|    └─LeakyReLU: 2-8                         --\n",
      "|    └─ModuleList: 2-9                        --\n",
      "|    |    └─TemporalBlock: 3-8                16,704\n",
      "|    |    └─TemporalBlock: 3-9                51,520\n",
      "├─Flatten: 1-4                                --\n",
      "├─Linear: 1-5                                 579\n",
      "├─LeakyReLU: 1-6                              --\n",
      "======================================================================\n",
      "Total params: 211,587\n",
      "Trainable params: 211,587\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "├─TCN: 1-1                                    --\n",
       "|    └─ModuleList: 2-1                        --\n",
       "|    |    └─Conv1d: 3-1                       2,112\n",
       "|    └─LeakyReLU: 2-2                         --\n",
       "|    └─ModuleList: 2-3                        --\n",
       "|    |    └─TemporalBlock: 3-2                16,704\n",
       "|    |    └─TemporalBlock: 3-3                51,520\n",
       "├─TCN: 1-2                                    --\n",
       "|    └─ModuleList: 2-4                        --\n",
       "|    |    └─Conv1d: 3-4                       2,112\n",
       "|    └─LeakyReLU: 2-5                         --\n",
       "|    └─ModuleList: 2-6                        --\n",
       "|    |    └─TemporalBlock: 3-5                16,704\n",
       "|    |    └─TemporalBlock: 3-6                51,520\n",
       "├─TCN: 1-3                                    --\n",
       "|    └─ModuleList: 2-7                        --\n",
       "|    |    └─Conv1d: 3-7                       2,112\n",
       "|    └─LeakyReLU: 2-8                         --\n",
       "|    └─ModuleList: 2-9                        --\n",
       "|    |    └─TemporalBlock: 3-8                16,704\n",
       "|    |    └─TemporalBlock: 3-9                51,520\n",
       "├─Flatten: 1-4                                --\n",
       "├─Linear: 1-5                                 579\n",
       "├─LeakyReLU: 1-6                              --\n",
       "======================================================================\n",
       "Total params: 211,587\n",
       "Trainable params: 211,587\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = my_model(TRAIN_STEPS,HEA_FEA,COO_FEA,ELE_FEA,LSTM_DIM)\n",
    "#\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "03207183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dataloader,val_dataloader,seq_length,n_epochs):\n",
    "    \n",
    "    history = dict(train=[],val=[])\n",
    "    \n",
    "    best_loss = 10000\n",
    "    \n",
    "    mb = master_bar(range(1,n_epochs+1))\n",
    "    \n",
    "    for epoch in mb:\n",
    "        \n",
    "        model = model.train()\n",
    "        \n",
    "        train_losses = []\n",
    "        \n",
    "        for TrainXHeat,TrainYHeat,TrainXCool,TrainYCool,TrainXElec,TrainYElec in tqdm(train_dataloader):\n",
    "            \n",
    "            seq_inp_heat = TrainXHeat.to(device)\n",
    "            \n",
    "            seq_true_heat = TrainYHeat.to(device)\n",
    "            \n",
    "            seq_inp_cool = TrainXCool.to(device)\n",
    "            \n",
    "            seq_true_cool = TrainYCool.to(device)\n",
    "            \n",
    "            seq_inp_elec = TrainXElec.to(device)\n",
    "            \n",
    "            seq_true_elec = TrainYElec.to(device)\n",
    "                                    \n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            seq_pred_heat,seq_pred_cool,seq_pred_elec = model(seq_inp_heat,seq_inp_cool,seq_inp_elec)\n",
    "                        \n",
    "            loss_heat = criterion(seq_pred_heat,seq_true_heat)\n",
    "            \n",
    "            loss_cool = criterion(seq_pred_cool,seq_true_cool)\n",
    "            \n",
    "\n",
    "            loss_elec = criterion(seq_pred_elec,seq_true_elec)\n",
    "            \n",
    "            loss = loss_heat + loss_cool + loss_elec\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "        val_losses = []\n",
    "        \n",
    "        loss_cools = []\n",
    "        \n",
    "        loss_heats = []\n",
    "        \n",
    "        model = model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for ValidXHeat,ValidYHeat,ValidXCool,ValidYCool,ValidXElec,ValidYElec in val_dataloader:\n",
    "                \n",
    "                seq_inp_heat = ValidXHeat.to(device)\n",
    "            \n",
    "                seq_true_heat = ValidYHeat.to(device)\n",
    "            \n",
    "                seq_inp_cool = ValidXCool.to(device)\n",
    "            \n",
    "                seq_true_cool = ValidYCool.to(device)\n",
    "            \n",
    "                seq_inp_elec = ValidXElec.to(device)\n",
    "            \n",
    "                seq_true_elec = ValidYElec.to(device)\n",
    "                \n",
    "                seq_pred_heat,seq_pred_cool,seq_pred_elec = model(seq_inp_heat,seq_inp_cool,seq_inp_elec)\n",
    "               \n",
    "                loss_heat = criterion(seq_pred_heat,seq_true_heat)\n",
    "            \n",
    "                loss_cool = criterion(seq_pred_cool,seq_true_cool)\n",
    "\n",
    "                loss_elec = criterion(seq_pred_elec,seq_true_elec)\n",
    "            \n",
    "                loss = loss_heat + loss_cool + loss_elec     \n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                loss_cools.append(loss_cool.item())\n",
    "                \n",
    "                loss_heats.append(loss_heat.item())\n",
    "                                                                                         \n",
    "                                                                                        \n",
    "        train_loss = np.mean(train_losses)\n",
    "                                                                                         \n",
    "        val_loss = np.mean(val_losses)\n",
    "        \n",
    "        loss_cool_mean = np.mean(loss_cools)\n",
    "        \n",
    "        loss_heat_mean = np.mean(loss_heats)\n",
    "\n",
    "        history['train'].append(train_loss)\n",
    "                                                                                         \n",
    "        history['val'].append(val_loss)\n",
    "                                                                                         \n",
    "        if val_loss < best_loss:\n",
    "            \n",
    "            best_loss = val_loss\n",
    "            \n",
    "            torch.save(model.state_dict(), 'best_model_n_features_GRU_1.pt')\n",
    "            \n",
    "            print(\"saved best model epoch:\",epoch,\"val loss is:\",val_loss)\n",
    "            \n",
    "            print(\"cool val loss is:\",loss_cool_mean)\n",
    "            \n",
    "            print(\"heat val loss is:\",loss_heat_mean)\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "                                                                                         \n",
    "        scheduler.step(val_loss)\n",
    "                                                                                         \n",
    "    #model.load_state_dict(best_model_wts)\n",
    "                                                                                         \n",
    "    return model.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "662dc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,weight_decay=1e-5)\n",
    "criterion = torch.nn.MSELoss().to(device) \n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 5e-3, eta_min=1e-8, last_epoch=-1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=10, factor =0.5 ,min_lr=1e-7, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "adaaeec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 1 val loss is: 0.03980105725879019\n",
      "cool val loss is: 0.00500943880549378\n",
      "heat val loss is: 0.024995800700377335\n",
      "Epoch 1: train loss 0.08674796484410763 val loss 0.03980105725879019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss 0.01743635034818255 val loss 0.050832323391329155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 3 val loss is: 0.037396237084811386\n",
      "cool val loss is: 0.0032860066011463377\n",
      "heat val loss is: 0.016827694288539616\n",
      "Epoch 3: train loss 0.012600906615193601 val loss 0.037396237084811386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 4 val loss is: 0.032486115243624554\n",
      "cool val loss is: 0.0027535514884882355\n",
      "heat val loss is: 0.013580600858073343\n",
      "Epoch 4: train loss 0.009828693316506109 val loss 0.032486115243624554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 5 val loss is: 0.02946537716144865\n",
      "cool val loss is: 0.0021020774808923966\n",
      "heat val loss is: 0.013575193006545305\n",
      "Epoch 5: train loss 0.008388424259413716 val loss 0.02946537716144865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 6 val loss is: 0.028854259120469742\n",
      "cool val loss is: 0.0018130565824156458\n",
      "heat val loss is: 0.01568422659130936\n",
      "Epoch 6: train loss 0.007037666730119239 val loss 0.028854259120469742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train loss 0.006529060057954679 val loss 0.03061721558597955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train loss 0.006053583226997423 val loss 0.030918437140909107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train loss 0.00568353071013037 val loss 0.03191436192190105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train loss 0.005350385876722249 val loss 0.03106007022275166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train loss 0.004974346916724714 val loss 0.02889953325079246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train loss 0.004686269334171999 val loss 0.02970449956641956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train loss 0.0044432380826960145 val loss 0.028861455365338108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train loss 0.004307798840687064 val loss 0.029554453085769306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 15 val loss is: 0.02738999973305247\n",
      "cool val loss is: 0.0027426201082893053\n",
      "heat val loss is: 0.014760087223046205\n",
      "Epoch 15: train loss 0.004093547460968506 val loss 0.02738999973305247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train loss 0.004028133550077292 val loss 0.027958618392321197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train loss 0.00378595529825912 val loss 0.028184036978266457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 18 val loss is: 0.02602102505889806\n",
      "cool val loss is: 0.0022237223496300762\n",
      "heat val loss is: 0.012646461625329473\n",
      "Epoch 18: train loss 0.003580254177396741 val loss 0.02602102505889806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 19 val loss is: 0.02300212684680115\n",
      "cool val loss is: 0.0018722309640989724\n",
      "heat val loss is: 0.011270058806985617\n",
      "Epoch 19: train loss 0.0033817018241241153 val loss 0.02300212684680115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 20 val loss is: 0.02093452363359657\n",
      "cool val loss is: 0.00157972087088803\n",
      "heat val loss is: 0.009723616086623886\n",
      "Epoch 20: train loss 0.003281206892204292 val loss 0.02093452363359657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 21 val loss is: 0.01932934671640396\n",
      "cool val loss is: 0.0016813190357590263\n",
      "heat val loss is: 0.008791066028855064\n",
      "Epoch 21: train loss 0.0031889408603835274 val loss 0.01932934671640396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 22 val loss is: 0.017213764092461628\n",
      "cool val loss is: 0.0013840332024053416\n",
      "heat val loss is: 0.008264126848768105\n",
      "Epoch 22: train loss 0.0031778607555739405 val loss 0.017213764092461628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 23 val loss is: 0.016055358404462986\n",
      "cool val loss is: 0.0015422588066113267\n",
      "heat val loss is: 0.007953285080888732\n",
      "Epoch 23: train loss 0.0030753343746485846 val loss 0.016055358404462986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:22<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train loss 0.002979841235229317 val loss 0.016708667305382816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train loss 0.002946329331506446 val loss 0.017587107817896387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train loss 0.0029197591597415473 val loss 0.017719831317663193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train loss 0.0028706325109864417 val loss 0.01806699772450057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train loss 0.0027483961268376226 val loss 0.01769085960801352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train loss 0.0026648493796289667 val loss 0.01727439361539754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train loss 0.002675128196685317 val loss 0.018025502012195913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train loss 0.002638496136612001 val loss 0.018589992076158524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train loss 0.0027029234888644215 val loss 0.021179692608050325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train loss 0.0026717021522448866 val loss 0.021732994058931417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train loss 0.002612621228029173 val loss 0.02281816185198047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train loss 0.0031477270911320905 val loss 0.022351413203234024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train loss 0.003029272841298384 val loss 0.01731586113402789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 37 val loss is: 0.015055461913685907\n",
      "cool val loss is: 0.0029092202669496396\n",
      "heat val loss is: 0.008159603463189507\n",
      "Epoch 37: train loss 0.0027263749455333527 val loss 0.015055461913685907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train loss 0.002527356495099151 val loss 0.01530963715843179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train loss 0.002405718447445966 val loss 0.016521985600279135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: train loss 0.002353304659318126 val loss 0.0171256197870455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: train loss 0.0022691539160802333 val loss 0.01681192270056768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: train loss 0.0022339119781967375 val loss 0.01802023017609661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: train loss 0.002180206497853508 val loss 0.01758702239021659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: train loss 0.0021367652722669352 val loss 0.01692136279730634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: train loss 0.002126484472870809 val loss 0.017403912053189495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: train loss 0.0020555803140170628 val loss 0.016065733337944203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: train loss 0.0020347488497519436 val loss 0.015593547585674307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 48 val loss is: 0.014910619155588474\n",
      "cool val loss is: 0.0017856094054877758\n",
      "heat val loss is: 0.006537128335118971\n",
      "Epoch 48: train loss 0.002010987559169478 val loss 0.014910619155588474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 49 val loss is: 0.014734767758372154\n",
      "cool val loss is: 0.0018066530332858251\n",
      "heat val loss is: 0.006535219092091376\n",
      "Epoch 49: train loss 0.001987169052369263 val loss 0.014734767758372154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 50 val loss is: 0.0136521918783811\n",
      "cool val loss is: 0.001471984276907857\n",
      "heat val loss is: 0.006410708344033496\n",
      "Epoch 50: train loss 0.0019630915501719 val loss 0.0136521918783811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: train loss 0.0019876201059931603 val loss 0.013894445728510618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 52 val loss is: 0.01281942164694721\n",
      "cool val loss is: 0.0015388264701786366\n",
      "heat val loss is: 0.005965932330582291\n",
      "Epoch 52: train loss 0.0019543064818848713 val loss 0.01281942164694721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 53 val loss is: 0.012608360414477911\n",
      "cool val loss is: 0.001599630909781395\n",
      "heat val loss is: 0.0058251226013949645\n",
      "Epoch 53: train loss 0.0019459636786847677 val loss 0.012608360414477911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 54 val loss is: 0.012363541109318083\n",
      "cool val loss is: 0.0013783317514356565\n",
      "heat val loss is: 0.005814773094078357\n",
      "Epoch 54: train loss 0.001929295290821175 val loss 0.012363541109318083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 55 val loss is: 0.01212819293141365\n",
      "cool val loss is: 0.0014408277003729547\n",
      "heat val loss is: 0.006056782726029103\n",
      "Epoch 55: train loss 0.001913628907395448 val loss 0.01212819293141365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 56 val loss is: 0.011904263995926489\n",
      "cool val loss is: 0.0014137280271494421\n",
      "heat val loss is: 0.005900691914245148\n",
      "Epoch 56: train loss 0.0018958255379163428 val loss 0.011904263995926489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 57 val loss is: 0.011802666926417838\n",
      "cool val loss is: 0.001639310588044199\n",
      "heat val loss is: 0.00606714669001204\n",
      "Epoch 57: train loss 0.001870486993526279 val loss 0.011802666926417838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 58 val loss is: 0.011672524100338871\n",
      "cool val loss is: 0.0018768635517600078\n",
      "heat val loss is: 0.005922342782882465\n",
      "Epoch 58: train loss 0.0018881389121371956 val loss 0.011672524100338871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: train loss 0.0018701904489956097 val loss 0.012550646481527523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: train loss 0.0018612624981173887 val loss 0.0127380226992748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: train loss 0.0018829745997482378 val loss 0.01300772080536593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: train loss 0.0018735836938290284 val loss 0.014103731521489945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: train loss 0.0018673825483253234 val loss 0.014388553925197233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: train loss 0.0018942270752046904 val loss 0.014696373942900787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: train loss 0.001895582560830238 val loss 0.013375219253992493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: train loss 0.0019080935058647442 val loss 0.012278215917335316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 67 val loss is: 0.011638312177224592\n",
      "cool val loss is: 0.0011572375832739372\n",
      "heat val loss is: 0.006032449092758311\n",
      "Epoch 67: train loss 0.0020021326586324283 val loss 0.011638312177224592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: train loss 0.0020361155096087344 val loss 0.012824142140082338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: train loss 0.002066609579763712 val loss 0.013232349799099293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: train loss 0.001950623137721171 val loss 0.013538380068811503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: train loss 0.0019726961735797776 val loss 0.01494100960818204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: train loss 0.00204109265376101 val loss 0.014835809145800093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: train loss 0.0019548345040726724 val loss 0.014142148747024212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: train loss 0.0019514664388349183 val loss 0.013405280484055931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: train loss 0.001869691335519627 val loss 0.012513919902796095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: train loss 0.0018093925408861587 val loss 0.011887552703476766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: train loss 0.0017657618851623905 val loss 0.01182621522721919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: train loss 0.0017144000537566702 val loss 0.012245014479214495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: train loss 0.0019180234682859914 val loss 0.014143515589900992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: train loss 0.0017785429929934023 val loss 0.014599011787636713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: train loss 0.001739770562077562 val loss 0.013365461872043934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: train loss 0.0017245412736414045 val loss 0.012585937172513117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: train loss 0.0016805382137746493 val loss 0.012148004787212069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: train loss 0.0016802353527563068 val loss 0.011954432607374409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: train loss 0.0016472879070307657 val loss 0.012093007903207432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: train loss 0.0016537482411373284 val loss 0.011982540473003279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: train loss 0.001628618417668458 val loss 0.011657356602055106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 88 val loss is: 0.01149175923571668\n",
      "cool val loss is: 0.0013060196546245027\n",
      "heat val loss is: 0.0067379291021180425\n",
      "Epoch 88: train loss 0.001620677636472832 val loss 0.01149175923571668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: train loss 0.0016127699360846074 val loss 0.011630639201030135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: train loss 0.0016016067394291535 val loss 0.011665272589942271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model epoch: 91 val loss is: 0.011490900937298482\n",
      "cool val loss is: 0.0012645147336033087\n",
      "heat val loss is: 0.006708215191875669\n",
      "Epoch 91: train loss 0.0015893822061466359 val loss 0.011490900937298482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: train loss 0.0015679586166625257 val loss 0.011573394083163956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: train loss 0.0015814378603466485 val loss 0.01178149493749846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: train loss 0.0015639084196723823 val loss 0.011931174477054314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: train loss 0.0015689239622981336 val loss 0.011610036737031558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: train loss 0.0015537717033662951 val loss 0.011555284177037802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: train loss 0.0015535536719521097 val loss 0.011935225010595539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: train loss 0.001548905447814089 val loss 0.012536970559846271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: train loss 0.0015457066485413432 val loss 0.012547603723677721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: train loss 0.0015658052163220453 val loss 0.012333521280776371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: train loss 0.0015565270979936833 val loss 0.012116474988446995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: train loss 0.0015432090031752635 val loss 0.012149419635534286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: train loss 0.0015431900774872044 val loss 0.012428024106404999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: train loss 0.001537939889669121 val loss 0.012334399898959831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: train loss 0.0015370197754851738 val loss 0.012316251639276743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: train loss 0.0015175739847595843 val loss 0.012566806409846653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: train loss 0.0015280507381966102 val loss 0.012709288984875788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: train loss 0.0015072563016555434 val loss 0.012428180483931845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: train loss 0.0015037319313586108 val loss 0.012780862267721783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: train loss 0.0015035121654654402 val loss 0.01302535209635442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: train loss 0.0015322421958884269 val loss 0.012990881053900177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: train loss 0.0015425828335797983 val loss 0.013139013666659594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: train loss 0.0015241519308609652 val loss 0.012987915257161314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: train loss 0.0015179311458738476 val loss 0.012965148695829239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: train loss 0.0015108547063583744 val loss 0.01299829383126714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: train loss 0.0014983933752931724 val loss 0.013054034461013296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: train loss 0.0015130387457905276 val loss 0.012896401596001604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: train loss 0.0014902154115430941 val loss 0.012916784225539728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: train loss 0.0014984296968735824 val loss 0.012866263912821358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: train loss 0.001479868467201964 val loss 0.012971347324888815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: train loss 0.0014908871760465066 val loss 0.012955171521753073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: train loss 0.0015153841507957785 val loss 0.013035090724852953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: train loss 0.0014917265078350202 val loss 0.013119120023805986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: train loss 0.0015052133963985518 val loss 0.0130297000604597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: train loss 0.0015172842920631031 val loss 0.01303959625180472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: train loss 0.0014961955037532033 val loss 0.013049058827825567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: train loss 0.0014922372251311797 val loss 0.0131323791786351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: train loss 0.001486300311254626 val loss 0.013055045030672442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: train loss 0.001480626235847217 val loss 0.013109102718193422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: train loss 0.0015002297234236145 val loss 0.013130569957535376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: train loss 0.0015057887143604108 val loss 0.01314285190098665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: train loss 0.001468689472768718 val loss 0.013123879928819158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: train loss 0.0014927415338458554 val loss 0.01322095367041501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:21<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: train loss 0.001481216132915207 val loss 0.01320570038462227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135: train loss 0.0014857115891342327 val loss 0.013195546259256926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136: train loss 0.0014870848218110247 val loss 0.013211841271682219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137: train loss 0.001475475791365153 val loss 0.013229392595927824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138: train loss 0.0014792392538650564 val loss 0.01321084928614172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139: train loss 0.0014661458796961452 val loss 0.013185271569951014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: train loss 0.0014637294597049275 val loss 0.01318401237949729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141: train loss 0.0014654040695146215 val loss 0.013181388039480556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:20<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142: train loss 0.0014785728920163684 val loss 0.013227231927554716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143: train loss 0.0014617377777360904 val loss 0.013192206240174446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144: train loss 0.0014508600478462805 val loss 0.01322479694235054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145: train loss 0.0014773773968420887 val loss 0.013233238450166855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146: train loss 0.0014642089418957596 val loss 0.013200139584527775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147: train loss 0.001450166440166603 val loss 0.013218616050752726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148: train loss 0.0014594254098141766 val loss 0.01318945854224942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: train loss 0.0014568149049858181 val loss 0.013204700990834019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: train loss 0.001462596903681895 val loss 0.013184474188495766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: train loss 0.0014606634463170465 val loss 0.013196269642900337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152: train loss 0.0014648852927802664 val loss 0.0132236106490547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153: train loss 0.0014608499037644044 val loss 0.013205662962387909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:18<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154: train loss 0.0014662933369175893 val loss 0.013199798889796843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155: train loss 0.001472761660230569 val loss 0.013206582389433275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: train loss 0.0014481990346182226 val loss 0.013202788519927046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157: train loss 0.001454411214436164 val loss 0.013175407593900507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158: train loss 0.00143871747504946 val loss 0.013184906703165987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159: train loss 0.0014578733019893683 val loss 0.01316722571341829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:19<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160: train loss 0.00145201458723586 val loss 0.013182250782847404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [01:14<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161: train loss 0.0014579247895348379 val loss 0.013189403594217518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162: train loss 0.0014554664783372146 val loss 0.01319106397303668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163: train loss 0.0014640703502749508 val loss 0.013167340901087631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164: train loss 0.001455672588111929 val loss 0.01318506837229837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165: train loss 0.0014435048368125454 val loss 0.013187331782484596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166: train loss 0.001445339882512415 val loss 0.013182892337102781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167: train loss 0.001443827160231839 val loss 0.013181725643913855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:55<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168: train loss 0.0014534678825006728 val loss 0.013178470671515573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169: train loss 0.001455419216449307 val loss 0.013173157730224457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: train loss 0.001440341964237252 val loss 0.013171361886303534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171: train loss 0.001451518480335865 val loss 0.013172454624013468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172: train loss 0.001451573121206214 val loss 0.013163370376622135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173: train loss 0.001444713520531066 val loss 0.013170216359536756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:53<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174: train loss 0.0014597082493100929 val loss 0.01316281585869464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175: train loss 0.0014492353312933529 val loss 0.013174227946861223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: train loss 0.0014446917639831037 val loss 0.01316605368629098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: train loss 0.0014524171907703957 val loss 0.013164519882676277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178: train loss 0.001436080408671722 val loss 0.013161598577756773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: train loss 0.0014521212108267096 val loss 0.013170825275169178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180: train loss 0.0014526766346124802 val loss 0.013169746549630707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181: train loss 0.0014390711450704456 val loss 0.013168519532138651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182: train loss 0.0014449486327510624 val loss 0.013167161071165041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183: train loss 0.001438745475393838 val loss 0.013164755591953342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184: train loss 0.0014439888381587228 val loss 0.013162980194796215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185: train loss 0.0014504605645703002 val loss 0.013162271839312532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:53<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186: train loss 0.0014420895976071278 val loss 0.013161204755306244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187: train loss 0.0014632363036327378 val loss 0.013161348644644022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:53<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188: train loss 0.0014664744083800227 val loss 0.01316510174762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189: train loss 0.001450860730488238 val loss 0.013160802254622633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190: train loss 0.0014547593317742289 val loss 0.01315890375355428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:53<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191: train loss 0.0014481858496265617 val loss 0.013154499317434702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192: train loss 0.001455941032552698 val loss 0.013156462291424925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193: train loss 0.0014341083008734762 val loss 0.013158139772713184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:53<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194: train loss 0.0014550648670656684 val loss 0.01316372902047905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195: train loss 0.0014451062022555322 val loss 0.013158642094243656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:53<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196: train loss 0.0014597380437074937 val loss 0.013158592903478579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197: train loss 0.0014499714267396417 val loss 0.013160573191602121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198: train loss 0.001456879318594504 val loss 0.013160389170727947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: train loss 0.00145189635408605 val loss 0.013163304676047781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 213/213 [00:54<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: train loss 0.0014580637260292058 val loss 0.01316407322883606\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\n",
    "  model,\n",
    "  train_dataloader,\n",
    "  val_dataloader,\n",
    "  seq_length=TRAIN_STEPS,\n",
    "  n_epochs=MAX_EPOCH, #Train for few epochs as illustration, \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "86e377aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b9865df130>]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train'])\n",
    "plt.plot(history['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "24f99134",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_heat = []\n",
    "\n",
    "test_losses_cool = []\n",
    "\n",
    "test_losses_elec = []\n",
    "\n",
    "heat_pred_total = []\n",
    "\n",
    "cool_pred_total = []\n",
    "\n",
    "elec_pred_heat = []\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "for ValidXHeat,ValidYHeat,ValidXCool,ValidYCool,ValidXElec,ValidYElec in tes_dataloader:\n",
    "                \n",
    "    seq_inp_heat = ValidXHeat.to(device)\n",
    "            \n",
    "    seq_true_heat = ValidYHeat.to(device)\n",
    "            \n",
    "    seq_inp_cool = ValidXCool.to(device)\n",
    "            \n",
    "    seq_true_cool = ValidYCool.to(device)\n",
    "            \n",
    "    seq_inp_elec = ValidXElec.to(device)\n",
    "            \n",
    "    seq_true_elec = ValidYElec.to(device)\n",
    "                \n",
    "    seq_pred_heat,seq_pred_cool,seq_pred_elec = model(seq_inp_heat,seq_inp_cool,seq_inp_elec)\n",
    "    \n",
    "    heat_pred_total.append(seq_pred_heat)\n",
    "    \n",
    "    cool_pred_total.append(seq_pred_cool)\n",
    "    \n",
    "    elec_pred_heat.append(seq_pred_elec)\n",
    "    \n",
    "    loss_heat = criterion(seq_pred_heat,seq_true_heat)\n",
    "            \n",
    "    loss_cool = criterion(seq_pred_cool,seq_true_cool)\n",
    "\n",
    "    loss_elec = criterion(seq_pred_elec,seq_true_elec)\n",
    "    \n",
    "    test_losses_heat.append(loss_heat.item())\n",
    "    \n",
    "    test_losses_cool.append(loss_cool.item())\n",
    "    \n",
    "    test_losses_elec.append(loss_elec.item())\n",
    "            \n",
    "    loss = loss_heat + loss_cool + loss_elec     \n",
    "                \n",
    "    test_losses.append(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9b301742",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_pred_total = torch.cat(heat_pred_total,dim=0).detach().numpy()\n",
    "cool_pred_total = torch.cat(cool_pred_total,dim=0).detach().numpy()\n",
    "elec_pred_heat = torch.cat(elec_pred_heat,dim=0).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a8d3ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = heat_test_scaler.inverse_transform(np.repeat(heat_pred_total.flatten().reshape(-1,1),29,axis=1))\n",
    "real_labs = heat_test_scaler.inverse_transform(np.repeat(heat_tes_lab.flatten().reshape(-1,1),29,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b68df45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The heating load MAPE is 6.090857293919761 %\n",
      "The heating load RMSE is 163.03716339441192 kW\n"
     ]
    }
   ],
   "source": [
    "print(\"The heating load MAPE is \" + str(mean_absolute_percentage_error(real_labs[:,1],real_pred[:,1])*100) + \" %\")\n",
    "print(\"The heating load RMSE is \" + str(mean_squared_error(real_labs[:,1],real_pred[:,1],squared=False)) + \" kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "81e5967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred_cool = cool_test_scaler.inverse_transform(np.repeat(cool_pred_total.flatten().reshape(-1,1),29,axis=1))\n",
    "real_labs_cool = cool_test_scaler.inverse_transform(np.repeat(cool_tes_lab.flatten().reshape(-1,1),29,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "949328d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cooling load MAPE is 6.945306871380449 %\n",
      "The cooling load RMSE is 1550.0818097532733 kW\n"
     ]
    }
   ],
   "source": [
    "print(\"The cooling load MAPE is \" + str(mean_absolute_percentage_error(real_labs_cool[:,2],real_pred_cool[:,2])*100) + \" %\")\n",
    "print(\"The cooling load RMSE is \" + str(mean_squared_error(real_labs_cool[:,2],real_pred_cool[:,2],squared=False)) + \" kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a65c1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred_elec = elec_test_scaler.inverse_transform(np.repeat(elec_pred_heat.flatten().reshape(-1,1),29,axis=1))\n",
    "real_labs_elec = elec_test_scaler.inverse_transform(np.repeat(elec_tes_lab.flatten().reshape(-1,1),29,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "92c1d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The electric load MAPE is 3.2302382583778053 %\n",
      "The electric load RMSE is 786.5625420553486 kW\n"
     ]
    }
   ],
   "source": [
    "print(\"The electric load MAPE is \" + str(mean_absolute_percentage_error(real_labs_elec[:,0],real_pred_elec[:,0])*100) + \" %\")\n",
    "print(\"The electric load RMSE is \" + str(mean_squared_error(real_labs_elec[:,0],real_pred_elec[:,0],squared=False)) + \" kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f7a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8996c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945c8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbfcf24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212cc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be3d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80a2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9791ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343a170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ddf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d872a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca99934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c734d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3b827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b868d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c62625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2357f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500c25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c48c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1705f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fd71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bcbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8a008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0f853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74794755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00d846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79fe9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1b21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd763ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
